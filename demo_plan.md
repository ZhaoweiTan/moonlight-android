# VR KPI/KEI Demo Plan

Version | Time | Author | Summary
--- | --- | --- | ---
0.1 | Aug. 11 | Zhaowei | Initial draft
0.2 | Aug. 13 | Zhaowei | Add compilation and overlay plan
0.3 | Aug. 20 | Zhaowei | Overlay, MI integration

## Goal:
Implement a VR demo application, where the real time statistics and MobileInsight KPI/KEIs are displayed in the front end. Strong correlation should be observed among the three.


## Implementation Plan:
* First stage: Implement a video streaming Android application. Record the useful performance metrics and link that with our KPI/KEI.
* Second stage: Overlay the statistics in a real VR application. The stats need to be displayed inside the headset.



## Implementation Details: Stage One
This section describes the implementation details for realizing an Android video streaming app which collects the video stats. Meanwhile, it also receives real-time MobileInsight KPI data, which is logged together with the in-app stats.

### Target application
We use the [Moonlight](https://github.com/moonlight-stream/moonlight-android), a cross platform game streaming client application.

The reason why we use this, is because Moonlight serves as the video streaming kernel of VR application StreamTheater. By modifying the Moonlight source code we are effectively making progress for stage two as well.


### Modification roadmap
* Compile the application from source code
* Get the video statistics
* Integration with MobileInsight (Need help from Zhehui)
* Display in-app stats together with KPI/KEI

I will use this weekend to finish the first two.

### Compilation details
First we download the source from the Github. `git clone https://github.com/ZhaoweiTan/moonlight-android.git`.

Download all the submodules `git submodule update --init --recursive`.

We then create a new file under the directory `vi local.properties`.

Add a line in the file to set the ndk path. It usually looks like `ndk.dir=/Users/[username]/Library/Android/sdk/ndk-bundle
`. Note that Android Studio is possible to automatically set this file.

Update the platform tools, sdk, etc. according to the hints by Android Studio. You can now compile it. In my case, I have to disable instant 


### Files Regarding Downlink Video Frames
Upon receiving of dl video frames, we could derive and get the real-time in-app quality statistics.

The major file I am going to modify is [MediaCodecDecoderRenderer.java](https://github.com/moonlight-stream/moonlight-android/blob/master/app/src/main/java/com/limelight/binding/video/MediaCodecDecoderRenderer.java). In this file, a bunch of metrics have already been provided by Moonlight, including total frames (`totalFrames`), total frame losses(`framesLost`), average decode latency(`getAverageDecoderLatency`), etc. I plan on writing new functions to record extra metrics. Some useful ones I could think of include real-time FPS, frame loss rate in a recent short period of time, etc.


### Files Regarding Uplink Motion 
Although this might not be used in KPI/KEI demo (since application-defined uplink action pattern seems not to be affected by the network), I mark them here in case we need them later on (e.g. adjust the uplink packet according to KEI).

The most related file is [Game.java](https://github.com/moonlight-stream/moonlight-android/blob/fa560f462fa28b08756599857dc509572c9229a8/app/src/main/java/com/limelight/Game.java). The critical piece is a handler which processes each event generated by the mobile client (`handleMotionEvent`). In this handler we are able to record the uplink event time, the periodicity, etc.

Note that this event handler calls several Nvidia native functions to use the socket and send packets etc. That Nvidia module is not open source. That being said, this function is probably the deepest we could go for recording the uplink stats. It should be enough though.



## Implementation Details: Stage Two

### Overlay Implementation Plan
In the decoder file, we have aan object `MediaCodec videoDecoder`. Video Decoder will read from buffer in `startRendererThread`; it uses `releaseOutputBuffer()` to render and output the frame out of the buffer.

The output frame is written in a surface. This surface (`SurfaceHolder renderTarget`) is set in function `setup()`. `videoDecoder.configure(videoFormat, renderTarget.getSurface(), null, 0);`.

Thinking of manupulating the renderTarget using [OpenGL ES](https://developer.android.com/guide/topics/graphics/opengl.html).

Server IP address: 131.179.80.180


### Integration with MobileInsight
The Broadcast receiver is written in `Game.java`. In this receiver, the received parameters are stored as private variables in the class.

Currently the parameters being tracked are:
```
UL_LAT_BREAKDOWN:{
'pkt_size': string, 'wait_delay': string, 'proc_delay': string, 'trans_delay': string
}
```

To support new intent or new parameters, create new local variable in the class (like in line 131), and modify the b-receiver (like in line 140-151).



### Overlay Implementation
Now we add the overlay got from both in-app and from MobileInsight. A background thread, `statsThread`, is created when the you load the game activity. In this thread, currently, it detects whether there's new info got from MI. If so, it updates the overlay text value. If you intend to change the content of the overlay (e.g. add a new local variable in the overlay), simply modify the value of `String stats`.

If you want to change the logic, or display some extra in-app stats, please contact me.





### Compiling StreamTheater
For compilation StreamTheater, I will consult Zhehan and figure things out this week.
